{"componentChunkName":"component---src-pages-search-tsx","path":"/search/","result":{"data":{"allMarkdownRemark":{"edges":[{"node":{"rawMarkdownBody":"\n\n이 글은 deeplearning.ai의 NLP Specialization를 참고하여 나이브 베이즈 모델을 텍스트 감정 분석에 초점을 맞춰 정리한 글입니다.\n\n\n## 0. 모델 개략\n나이브 베이즈 모델은 분류 과제를 위한 확률 모델이다. 훈련 데이터에 등장하는 모든 단어의 빈도를 세어서 각 데이터에 대한 조건부 확률의 비율을 계산하므로 분류 과제를 수행하는데 적합하다.\n\n### 나이브 베이즈 모델은\n- 훈련과 예측을 빠르게 수행할 수 있으므로 baseline 모델로 적합하다.\n- 문장에 있는 각 단어들이 독립적이라고 가정하기 때문에, 문장 내 단어들의 관계를 측정하거나 문장 내의 빈칸을 채우는 등의 과제에는 적합하지 않다.\n- 훈련 데이터 내 단어들이 등장하는 빈도에 기반하기 때문에, 훈련 데이터에 포함되지 않은 새로운 단어에 대한 예측이나 단어의 순서를 판단하는 과제에는 적합하지 않다.\n- 감정 분석, 저자 분류, 스팸 필터링, 문서 요약, 동음이의어 구분 등의 과제에 활용할 수 있다.\n\n이 글에서는 나이브 베이즈 모델로 이진 분류를 수행하는 상황을 가정하겠다. 특히 어떤 문장을 입력 받아서 문장이 긍정적인 정서를 포함하고 있으면 `1`을, 부정적인 정서를 내포하고 있으면 `0`을 반환하는 감정 분석(sentiment analysis) 과제를 수행한다.\n\n```python\ninput_s = 'hope you get well soon.'\nmodel(input_s) # 1, 긍정\n\ninput_s = 'the class was in a terrible mood...'\nmodel(input_s) # 0, 부정\n```\n_위와 같은 작업을 수행하는 모델 `model`을 얻는 것이 목적이다._\n\n\n\n## 1. 조건부 확률과 베이즈 룰\n모델을 살펴보기에 앞서 조건부 확률과 베이즈 룰에 대해 알아보자.\n\n### 🎲 조건부 확률(Conditional Probability) 이란?\n모수에서 조건 A가 만족될 확률을 $P(A)$, 조건 B가 만족될 확률을 $P(B)$라고 하자. 이때 B에 대한 A의 조건부 확률 $P(A|B)$ 는 조건 B를 만족하는 표본에서 조건 A를 만족하는 표본을 선택할 확률을 의미한다. 즉 $P(A|B)$는 조건 A와 B를 모두 만족하는 표본을 선택할 확률인 $P(A \\cap B)$에 모수에서 조건 B를 만족하는 표본을 선택할 확률 $P(B)$를 나눈 값으로 정의된다.\n\n$$\nP(A|B) =\\frac{P(A \\cap B)}{P(B)}\n$$\n\n조건부 확률은 뽑을 샘플의 범위를 표본 대신 조건으로 제한하는 효과가 있다. \n\n### 🎲 베이즈 정리란\n위의 정의로 부터 두개의 조건부 확률을 표현 할 수 있다.\n\n$$\nP(A|B) = \\frac{P(A \\cap B)}{P(B)} \\\\\nP(B|A) = \\frac{P(A \\cap B)}{P(A)} \n$$\n\n예를 들어 조건 `A`가 `20대`이고 조건 `B`가 `심장병`이라고 하자. 몇 개의 병원에서 표본 집단을 모아서 **심장병에 걸린 사람이 20대일 비율**을 조사하고자 한다. 우리는 표본 집단 데이터베이스로 부터 **심장병이 걸린 사람의 비율**과 **20대의 비율**을 알고있으며, 나아가 **20대 중에서 심장병에 걸린 사람의 비율**을 알 수 있다. 베이즈 정리는 우리가 알고있는 정보로 부터 우리가 원하는 정보를 얻을 수 있다는 것을 증명한다. 대수 연산을 통해 $P(A|B)$를 $P(B|A)$에 대해 다음과 같이 표현할 수 있다.\n\n$$\nP(A|B) = \\frac{P(A)}{P(B)} \\times P(B|A) ...... (*)\n$$\n\n두 조건의 조건부 확률의 관계를 나타내는 수식 `(*)`을 `베이즈 정리`라고 한다. 이때 $P(A)$를 `사전확률(prior)`, $P(A|B)$를 `사후확률(posterior)`, 그리고 $P(B|A)$를 `우도(likelihood)`라고 부른다.\n\n\n## 3. 조건부 빈도 세기\n텍스트가 내포하는 감정을 이진 분류하기 위해 분류 클래스를 $class \\in \\{positive, negative\\}$로 정의하자. $m$개의 단어를 포함하는 corpus에 속하는 단어 $w_i \\in corpus$에 대해 우리가 구하고자 하는 값은 $P(class|w_i)$, 즉 단어가 주어졌을 때 단어가 특정 class에 속할 확률을 구하는 것이다. 베이즈 정리를 떠올려 보면:\n\n$$\nP(class|w_i) = \\frac{P(class) \\cdot P(w_i|class)}{P(w_i)}\n$$\n\n이며 $P(w_i)$는 $w_i$에 대한 상수값이므로 확률을 계산할 때 무시할 수 있다. 우리는 문장을 입력받아 각 단어의 조건부 확률을 계산해서 나이브 가정에 따라 한 문장의 조건부 확률을 반환하고자 한다. 따라서 **나이브** 베이즈 모델의 아이디어를 수식으로 나타내면 예측하고자 하는 문장 $sentence$에 속한 모든 단어 $w_i \\in sentence$ ($i=1, .., n$)에 대해 다음과 같이 쓸 수 있다: \n\n$$\n\\hat{y} = argmax_{class} P(class) \\prod_{i=1}^{n}P(w_i|class)\n$$\n\n위 식은 최대 우도 추정(Maximum Likelihood Estimation, MLE)의 아이디어이기도 하다. 우선은 corpus에 대한 조건부 빈도인 $P(w_i|class)$를 계산해야 한다.\n\n다시 베이즈 정리에 의해, 클래스에 대한 조건부 확률을 다음과 같이 계산할 수 있다.\n\n$$\n\\begin{aligned}\nP(w | class) &= \\frac{P(w \\cap class)}{P(class)} \\\\\n&= \\frac{freq(w, class)}{N_{class}}\n\\end{aligned}\n$$\n\n위 식에서 $freq(w, class)$는 $class$에서 $w$가 나타나는 횟수로, $P(w \\cap class)$와 같다. $N_{class}$는 클래스에 포함되는 모든 단어의 빈도이다.\n\n### 🎲 Laplacian Smoothing\nLaplacian Smoothing은 조건부 확률이 0에 가까운 작은 수가 되는 것을 방지하기 위해 사용하는 전산 기법이다. Laplacian Smoothing을 조건부 확률에 적용하면 bias를 추가하여 다음과 같이 표현할 수 있다.\n\n$$\nP(w|class) = \\frac{freq(w, class) + 1}{N_{class} + V_{class}}\n$$\n\n따라서:\n\n$$\n\\sum_{w}P(w|class) = \\frac{\\sum_w freq(w,class) + V_{class}}{N_{class} + V_{class}}\n$$\n\n $V_{class}$는 클래스에 등장하는 **유일한** 단어의 개수이다. 즉 모든 단어 $w$에 대해서 위의 조건부 확률을 더하면 분자에서 더한 $1$이 $V_{class}$ 만큼 모이는 구조이다.\n\n\n## 3. Likelihood 계산하기\n앞에서 표현한 최대 우도 추정 방식을 조금 변형해, 이 글에서는 `Likelihood-ratio` 방법을 통해 분류 작업을 수행하고자 한다. \n\n우선 ratio란 분류 $class$에 대한 조건부 확률의 비율이다. 임의의 단어 $w_i$에 대해 $ratio(w_i)$는 다음과 같이 정의할 수 있다.\n\n$$\nratio(w_i) = \\frac{P(w_i|Pos)}{P(w_i|Neg)}\n$$\n\nLikelihood란 표본을 결합 확률로 나타낸 함수이며, 여기서는 입력 문장$s$가 임의의 $class$일 확률을 의미한다. 여기서는 Likelihood를 ratio에 대해 정의하자. 즉 모든 입력값 $w_i \\in s$에 대해 ratio를 곱한 값으로 표현한다.\n\n$$\nlikelihood(s) = \\prod^{m}_{i=1}\\frac{P(w_i|Pos)}{P(w_i|Neg)}\n$$\n\n만약 입력값의 모든 단어 $w_i$가 corpus의 긍정적인 라벨과 부정적인 라벨에서 같은 빈도로 나타났다면 likelihood값은 `1`로 나타날 것이다. 이 결과를 긍정적이지도 부정적이지도 않은 `중립 값`이라고 볼 수 있다. 반면 분모 분자는 빈도 수이므로 likelihood는 음의 값을 가질 수 없고, 분모 $P(w_i|Neg)$가 분자 $P(w_i|Pos)$ 보다 커질 수록 0에 가까워지고 반대의 경우 양의 무한대 값에 가까워질 수 있다.\n\n### 🎲 Naive 란?\n베이즈 모델이 `naive`(순진하다)는 말은 모수의 모든 표본이 상호 독립적이고 완전하다고 가정하는 것을 뜻한다. 즉 머신 러닝 모델에서는 데이터의 모든 특성들(features)을 알 수 있고, 나아가 특성들이 서로 독립적이라고 가정하는 것을 뜻한다. 예를 들어 한 문장을 데이터 한개라고 하면, 문장에 속한 단어를 데이터의 특성들로 볼 수 있고 나이브 베이즈 모델은 이 단어들이 상호 연관(covariate) 되어있지 않다고 가정한다. \n\n문장이 class에 속할 확률은 결합 확률 $P(class, w_1, ..., w_n)$인데, 연쇄 법칙에 따르면:\n\n$$\n\\begin{aligned}\nP(class, w_1, ..., w_n) \n&= P(class) \\cdot P(w_1, ..., w_n) \\\\\n&= P(class) \\cdot P(w_1|class) \\cdot P(w_2, ..., w_n) \\\\\n&= P(class) \\cdot P(w_1|class) \\cdot P(w_2|class, w_1) \\cdot P(w_3, ..., w_n) \\\\\n&= ...\n\\end{aligned} \n$$\n\n이렇게 문장의 조건부 확률을 앞에 등장한 단어들과 class에 대한 조건부 확률 곱으로 나타낼 수 있다. 여기서 나이브 가정은 특성들 간의 관계를 부정하므로 임의의 쌍 $i \\neq j$에 대해 $P(w_i|class) = P(w_i|class, w_j)$를 만족한다. 따라서 문장의 조건부 확률을 보다 간단하게 표현할 수 있다.\n\n$$\n\\begin{aligned}\nP(class, w_1, ..., w_n) \n&= P(class) \\cdot P(w_1|class) \\cdot ... \\cdot P(w_n|class) \\\\\n&= P(class) \\cdot \\prod_{i=1}^{n} P(w_i|class)\n\\end{aligned} \n$$\n\n현실 세계의 많은 현상은 상호 의존적임에도 불구하고, 나이브 베이즈 모델은 오랫동안 효율적이고 효과적인 모델로 활용되어왔다.\n\n> [나이브 베이즈 모델의 효과 분석 자료 보기](https://web.archive.org/web/20171210133853/http://www.research.ibm.com/people/r/rish/papers/RC22230.pdf)\n\n### 🎲 로그값으로 계산하기\n확률은 0과 1 사이의 값이므로, 확률을 여러번 곱하면 전산적으로 언더플로우의 위험이 커진다. 너무 큰 값이나 너무 작은 값을 다루는 전형적인 방법은 로그를 사용하는 것이다. 로그를 취한 log likelihood는 log ratio의 합으로 쓸 수 있다.\n\n$$\n\\begin{aligned}\nlog\\_ ratio(w_i) &= log \\frac{P(w_i|Pos)}{P(w_i|Neg)} \\\\\nlog\\_ likelihood &= \\sum^{m}_{i=1} log \\frac{P(w_i|Pos)}{P(w_i|Neg)}\n\\end{aligned}\n$$\n\n한가지 개념을 추가하자면, log ratio의 값을 lambda 함수로 표현하기도 한다. 즉 $\\lambda(w)$를 log ratio로 표현하면 likelihood를 더 간단하게 쓸수 있다.\n\n$$\n\\begin{aligned}\n\\lambda(w_i) &= log\\frac{P(w_i|Pos)}{P(w_i|Neg)} \\\\\nlog\\_ likelihood(s) &= \\sum^{n}_{i=1} \\lambda(w_i)\n\\end{aligned}\n$$\n\n로그를 취하게 되면 likelihood의 중립 값은 $1$에서 $log 1 = 0$으로 변하게 된다. $0$에서 양의 무한대에 대한 로그값은 음의 무한대에서 양의 무한대이므로 log likelihood의 값의 범위도 $0$을 중립 값으로하는 음의 무한대에서 양의 무한대 값을 반환할 것이다.\n\n### 🎲 사전확률\n예를 들어 코로나 팬데믹에 대한 트윗을 모아서 감정 분석을 수행한다면, 부정적인 트윗이 긍정적인 트윗보다 많을 것이다. 현실 데이터 corpus에서 분류 클래스가 균등하게 나눠지는 경우는 드물기 때문에, 데이터의 불균형을 보정하기 위한 절차가 필요하다. \n\n나이브 베이즈 모델에서는 사전확률이 역할을 수행한다. Likelihood와 마찬가지로 사전확률을 class의 비율로 정의하고 로그값을 취할 수 있다. \n\n$$\nlog\\_prior = log \\frac{P(Pos)}{P(Neg)}\n$$\n\n어떤 입력값에 대해 log likelihood가 0이라고 하면, 예측값은 log prior와 거의 같을 것이다. \n\n## 4. 나이브 베이즈 모델\n다시 나이브 베이즈 연산을 보면, 입력 문장 $s$에 대해:\n\n$$\nNB = log\\frac{P(Pos)}{P(Neg)} + \\sum^{n}_{i=1} \\lambda(w_i)\n$$\n\n위의 식으로 계산되며, \n\n$$\nNB = log\\_prior + log\\_likelihood\n$$\n\n로 정리할 수 있다. 연산의 순서는 다음과 같이 정리할 수 있다. \n\n0. 훈련 데이터를 전처리 한다.\n1. 토큰화 된 단어의 빈도 $freq(w, class)$를 계산한다.\n2. 모든 훈련 데이터의 단어에 대해 훈련해 log prior와 log likelihood 값을 구한다.\n    - 모든 훈련 데이터의 단어에 대해 $P(w|Pos)$와 $P(w|Neg)$ 값을 구한다.\n    - 모든 훈련 데이터의 단어에 대해 $P(Pos)$와 $P(Neg)$ 값을 구한다.\n3. 훈련한 모델의 가중치로 정서를 예측한다.\n\n\n### 📂 구현하기\n\n#### 1. 토큰화 된 단어의 빈도 $freq(w, class)$를 계산한다.\n```python\ndef get_freq(dd, train_x, train_y):\n    '''\n    Get frequency dictionary from the training data.\n    input:\n        dd : a defaultdict of integer.\n        train_x : list of tokened sentences of training data.\n        train_y : list of 0 or 1 corresponding to the train_x. \n    return:\n        result : dictionary of (key, value) = (word label pair, frequency).\n    '''\n    for label, sentence in zip(train_y, train_x):\n        for word in process(sentence):\n            dd[(word, label)] += 1\n\n    return dd\n\n# count frequency dictionary from train_x and train_y.\nfreqs = get_freq(defaultdict(int), train_x, train_y)\n```\n\n#### 2. 모든 훈련 데이터의 단어에 대해 훈련해 log prior와 log likelihood 값을 구한다.\n```python\ndef train_naive_bayes(freqs, train_x, train_y):\n    '''\n    Train Naive Bayes model, that is, get prior and likelihood from the training data.\n    return:\n        log_prior : an integer. P(Pos) / P(Neg) value.\n        log_likelihood : a dictionary of (key, value) = (word, log likelihood)\n    '''\n    # log_likelihood relies on words\n    log_likelihood = {}\n    # log prior value relies on the corpus\n    log_prior = 0\n\n    # get unique words from the frequency dict\n    vocab = list(set(freq.keys()))\n    V = len(vocab)\n\n    # get N_pos and N_neg\n    N_pos = N_neg = 0\n    for pair in freqs.keys():\n        # if label is 1(> 0), the word is positive.\n        if pair[1] > 0:\n            N_pos += freqs[pair]\n        # if label is 0, the word is negative.\n        else:\n            N_neg += freqs[pair]\n\n    # get log likelihood\n    for w in vocab:\n        # get positive and negative frequency of word w.\n        freq_pos = freqs.get((w, 1), 0)\n        freq_neg = freqs.get((w, 0), 0)\n\n        # get P(w|Pos) and P(w|Neg).\n        p_w_pos = (freq_pos + 1) / (N_pos + V)\n        p_w_neg = (freq_neg + 1) / (N_neg + V)\n\n        log_likelihood[w] = np.log(p_w_pos) - np.log(p_w_neg)\n\n    # to compute log_prior,\n    # get the number of positive and negative labels\n    num_label = len(train_y)\n    num_pos = len(train_y[train_y == 1])\n    num_neg = len(train_y[train_y == 0])\n\n    # log prior = log(P(Pos)) - log(P(Neg))\n    log_prior = np.log(num_pos / num_label) - np.log(num_neg / num_label)\n\n    return log_prior, log_likelihood\n\n# get log prior and log likelihood from the training data\n# so that we can train on test data.\nlog_prior, log_likelihood = train_naive_bayes(freqs, train_x, train_y)\n```\n\n#### 3. 훈련한 모델의 가중치로 정서를 예측한다.\n```python\ndef predict_naive_bayes(s, log_prior, log_likelihood):\n    '''\n    input:\n        s : a list. Input sentence.\n        log_prior : log prior from trained naive bayes.\n        log_likelihood : log likelihood from trained naive bayes.\n    return:\n        log_prob : float between 0 and 1. probability that s is positive.\n    '''    \n    \n    words = proprocess(s)\n\n    log_prob = 0\n\n    for w in words:\n        if w in log_likelihood:\n            log_prob += log_likelihood[w]\n\n    log_prob += log_prior\n\n    return log_prob\n\n# print probability of test data.\ntest_data = 'hope you get well soon. it hurts to see you ill 😢'\nprint('prediction:', predict_naive_bayes(test_data, log_prior, log_likelihood))\n\n# output: 3.5905424260671044 -- 긍정 정서로 예측했다.\n```\n\n\n## 참고 자료\n1. Coursera, deeplearning.ai, Natural Language Processing with Classification and Vector Spaces, week 2 \n2. Wikipedia, Naive Bayes Classification, https://en.wikipedia.org/wiki/Naive_Bayes_classifier\n3. Wikipedia, Additive Smooothing, https://en.wikipedia.org/wiki/Additive_smoothing\n4. Wikipedia, Likelihood-ratio test, https://en.wikipedia.org/wiki/Likelihood-ratio_test","excerpt":"이 글은 deeplearning.ai의 NLP Specialization를 참고하여 나이브 베이즈 모델을 텍스트 감정 분석에 초점을 맞춰 정리한 글입니다. 0. 모델 개략 나이브 베이즈 모델은 분류 과제를 위한 확률 모델이다. 훈련 데이터에 등장하는…","fields":{"slug":"/naive_bayes/"},"frontmatter":{"date":"Mar 28, 2022","title":"나이브 베이즈 분류","tags":["NLP","Classification","Sentiment Analysis"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\n## 최단 경로 알고리즘\n\n그래프는 간선에 가중치 정보를 추가할 수 있다. 이런 그래프를 가중 그래프(weighted graph) 라고 하며, 자연스럽게 출발 노드에서 특정 노드로 가는 경로의 가중치 합이 최소가 되는 경로를 찾는 문제가 발생한다. 깊이 우선 탐색(DFS)에서 `경로의 개수를 최소화`하는 것이 목적이었다면 이 문제에서는 가중 그래프에서 `경로 가중치의 합을 최소화` 하는 것이 목적이며, 이 문제를 `최단 경로 알고리즘`이라고 부른다.\n\n이 글에서는 두개의 최단 경로 알고리즘을 정리하고자 한다.\n\n1. Dijkstra 알고리즘\n2. Floyd-Warshall 알고리즘\n\n## 1. Dijkstra 알고리즘\nDijkstra 알고리즘은 최단 경로 알고리즘으로, 시작 노드에서 모든 노드까지의 최단 경로를 계산한다. Dijkstra 알고리즘은 매 시점에서 가장 비용이 적은 노드를 선택하는 **그리디 알고리즘**이며, 이 때문에 가중치가 모두 양수(positive number)인 유향(directed) 그래프에 대해서만 작동한다.\n\n### 📂 우선 순위 큐를 활용한 Dijkstra 알고리즘 구현\nDijkstra 알고리즘은 우선 순위 큐를 활용한 재귀 함수로 구현할 수 있다. \n1. 저장된 최단 거리가 입력 받은 거리보다 짧은 경우, 함수를 종료한다.\n2. 1번에서 끝나지 않은 경우, 현재 노드에서 모든 연결된 노드로 가는 경로를 고려해, 이미 저장된 경로와 거리를 비교한다. 저장된 최단 거리가 계산한 거리보다 긴 경우, 더 짧은 거리로 dist 배열의 해당 값을 변경한다.\n3. 우선 순위 큐가 빌 때 까지 위 과정을 반복한다.\n\n_최단 거리를 정렬하기 위해 우선 순위 큐를 사용하지만, 큐를 사용하지 않고서도 알고리즘을 구현할 수 있다._\n\n#### 파이썬 코드\n```python\nfrom heapq import heappush, heappop\nfrom collections import defaultdict\n\n# 노드 개수 n과 간선 개수 m을 입력받는다.\nn, m = map(int, input().split())\n\n# 시작 노드를 입력 받는다.\nstart = int(input())\n\n# 1차원 배열 graph를 초기화한다.\ngraph = defaultdict(list)\n\n# graph[i]는 (node_number, weight)를 원소로 하는 리스트다.\nfor _ in range(m):\n    i, j, w = map(int, input().split())\n    graph[i].append(j, w)\n\n# graph와 노드 개수 n을 입력받아\n# `시작 노드`에서 `모든 노드`까지의 최단 거리를 반환한다. \ndef shortest_path(graph, n, start):\n\n    # distance[i] : 시작 노드에서 노드 i 까지의 최단 거리\n    # 큰 값으로 초기화한다.\n    INF = int(1e9)\n    distance = [INF] * (n + 1)\n\n    def dijkstra(start):\n        # q의 원소: (shortest_distance, node_number)\n        # 시작노드에서 시작노드까지의 거리는 0이다.\n        hq = []\n        heappush(hq, (0, start))\n        distance[start] = 0\n\n        # q가 존재하는 한 계속한다.\n        while hq:\n            dist, now = heappop(q)\n            # 저장된 최단 거리가 계산한 거리보다 짧은 경우, \n            # 변경하지 않는다.\n            if distance[now] < dist:\n                continue\n            # 연결된 노드에 대해 새로운 경로의 거리를 비교한다.\n            for n, d in graph[now]:\n                w_dist = dist + d\n                # 저장된 최단 거리가 계산한 거리보다 긴 경우, \n                # 더 짧은 거리로 dist 값을 변경한다.\n                if w_dist < distance[n]:\n                    distance[n] = w_dist\n                    heappush(hq, (w_dist, n))\n\n    # 시작노드에 대해 dijkstra를 구현한다.\n    dijkstra(start)\n    return distance\n\nshortest = shortest_path(graph, n, start))\nfor i in range(n):\n    print(f\"Shortest Path from node {start} to node {i}: {shortest[i+1]}\")\n```\n시간 복잡도는 우선 순위 큐의 정렬에 의해 노드 개수 $N$과 가중치 개수 $M$에 대해 $O(MlogN)$이다.\n\n## 2. Floyd-Warshall 알고리즘\n\nFloyd-Warshall 알고리즘은 모든 노드에서 모든 노드까지의 최단 경로를 계산하는 **다이내믹 프로그래밍** 알고리즘이다. 따라서 점화식을 알기만 하면 구현이 비교적 간단하다는 장점이 있다.\n\n`노드 i`에서 `노드 j`로 가는 임의의 경로가 있다고 하자. 만약 i에서 j로 가는 다른 경로가 있다면 이 경로는 임의의 경로가 지나지 않는 다른 노드를 거쳐갈 것이다. 다른 노드를 임의로 `노드 k`라고 할때, `노드 i`에서 `노드 k`로 다시 `노드 k`에서 `노드 j`로 가는 경로와 그렇지 않은 경로를 비교할 수 있다. $dist[i][j]$를 노드 i에서 j로 가는 최단 경로라고 정의하면 다음과 같이 점화식을 쓸 수 있다.\n$$\ndist[i][j] = min(dist[i][j], dist[i][k] + dist[k][j])\n$$\n따라서 노드 개수 N에 대해 $(N, N)$크기의 2차원 배열에 임의의 `노드 i`에서 임의의 `노드 j`로 가는 최단 경로를 저장한다. \n\n### 📂 Floyd-Warshall 알고리즘 구현\n1. 노드 개수 $N$에 대해 $(N, N)$ 크기의 2차원 배열을 초기화한다.\n2. 위의 점화식을 이용해 모든 k에 대해 2차원 배열을 순회한다.\n\n#### 파이썬 코드\n```python\n# 노드 개수 n과 간선 개수 m을 입력받는다.\nn, m = map(int, input().split())\n\n# 2차원 dist 배열을 큰 값으로 초기화 한다.\n# dist[i][j] : 노드 i에서 노드 j로 가는 최단 경로\nINF = 1e9\ndist = [INF for _ in range(n)] for _ in range(n)\n\n# 간선 개수만큼 간선 정보를 2차원 배열에 입력받는다.\nfor _ in range(m):\n    i, j, w = map(int, input().split())\n    dist[i][j] = w\n\n# dist와 노드 개수 n을 입력받아\n# `모든 노드`에서 `모든 노드`까지의 최단 거리를 저장한 2차원 배열을 반환한다. \ndef floyd_warshall(dist, n):\n    \n    for k in range(n+1):\n        for i in range(n+1):\n            for j in range(n+1):\n                # 저장되어 있는 최단 경로 dist[i][j]와\n                # 노드 k를 거치는 경로 dist[i][k] + dist[k][j]를 비교한다.\n                dist[i][j] = min(dist[i][j], dist[i][k] + dist[k][j])\n\n    return dist\n\nshortest = floyd_warshall(dist, n)\nfor i in range(n):\n    for j in range(n):\n        print(f\"Shortest Path from node {i} to node {j}: {shortest[i+1][j+1]}\")\n```\n\nFloyd-Warshall 알고리즘은 삼중 for문에 의해 시간 복잡도가 $O(N^3)$이므로 노드 개수가 많은 그래프는 수행시간에 유의해야 한다. \n\n---\n\n## 참고자료\n1. Youtube, (이코테 2021 강의 몰아보기) 7. 최단 경로 알고리즘, https://www.youtube.com/watch?v=acqm9mM1P6o","excerpt":"최단 경로 알고리즘 그래프는 간선에 가중치 정보를 추가할 수 있다. 이런 그래프를 가중 그래프(weighted graph) 라고 하며, 자연스럽게 출발 노드에서 특정 노드로 가는 경로의 가중치 합이 최소가 되는 경로를 찾는 문제가 발생한다. 깊이 우…","fields":{"slug":"/shortest_path/"},"frontmatter":{"date":"Mar 21, 2022","title":"최단 경로 알고리즘","tags":["Algorithms","Shortest Path","Dijkstra Algorithm","Floyd-Warshall Algorithm"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\n> 문제: [프로그래머스](https://programmers.co.kr/learn/courses/30/lessons/12978)\n\n## 문제 해결 아이디어\n\n그래프와 각 간선의 가중치가 주어질 때, 시작 노드에서 출발해 지나는 간선의 가중치를 모두 더해 도착할 때까지 `가중치의 합`이 `K` 이하가 되는 노드를 모두 찾는 문제다. 즉 시작노드에서 특정 노드까지 가중치 합을 최소로 하는 경로를 찾아야 하며, 이런 문제를 `최단 경로 알고리즘`이라고 부른다.\n\n> [최단 경로 알고리즘 알아보기](https://snowith.github.io/shortest_path/)\n\n이 문제는 Dijkstra 알고리즘을 구현하여 해결할 수 있다. \n1. 주어진 road의 정보를 한쪽 노드를 키로 하고 반대쪽 노드와 가중치를 값으로 하는 딕셔너리 형태로 저장한다.\n2. 다익스트라 알고리즘을 재귀 함수로 구현한다.\n    - 입력 받은 경로와 dist 배열에 저장된 값을 비교하여 업데이트한다.\n    - 시작 노드의 최소 경로에서 연결 된 노드를 연결한 경로에 대해 다익스트라 알고리즘을 실행한다. \n    \n3. 시작 노드인 1번 노드와 최단거리 0에 대해 다익스트라 알고리즘을 실행한다.\n4. K보다 작은 값들을 세어 반환한다.\n\n## 파이썬 코드\n```python\nfrom collections import defaultdict\n\ndef solution(N, road, K):\n    \n    # 시작 노드에서 각 노드까지의 거리를 큰 값으로 초기화 한다.\n    # 인덱스는 '주어진 노드 - 1'로 설정한다.\n    INF = 1e9\n    dist = [INF] * (N + 1)\n    dist[0] = 0\n\n    # road의 정보를 딕셔너리로 저장한다.\n    graph = defaultdict(list)\n    for a, b, c in road:\n        graph[a].append([b,c])\n        graph[b].append([a,c])\n    \n    # dijkstra를 구현한다.\n    # graph 딕셔너리와 시작노드 v, 최단 경로(시간) time이 주어졌을 때\n    # 함수 밖의 dist 배열에 경로의 최소값을 저장한다.\n    def dijkstra(start_node, time):\n        # 최단 경로만 저장한다.\n        if dist[start] > time:\n            dist[start] = time\n        # 연결된 노드에 대해 dijkstra를 실행한다.\n        for next_, t in graph[start]:\n            if t + time < dist[next_]:\n                dijkstra(graph, next_, t + time)\n    \n    # 1번 노드의 최단 경로가 0인 것에서 출발해서\n    # 모든 노드의 최단 경로를 찾는다.\n    dijkstra(graph, 1, 0)\n\n    # K 보다 작은 dist의 값들을 세어 반환한다.\n    cnt = 0\n    for n in range(N):\n        if dist[n] <= K:\n            cnt += 1\n\n    return cnt\n```\n","excerpt":"문제: 프로그래머스 문제 해결 아이디어 그래프와 각 간선의 가중치가 주어질 때, 시작 노드에서 출발해 지나는 간선의 가중치를 모두 더해 도착할 때까지 이  이하가 되는 노드를 모두 찾는 문제다. 즉 시작노드에서 특정 노드까지 가중치 합을 최소로 하는…","fields":{"slug":"/programmers. 배달/"},"frontmatter":{"date":"Mar 19, 2022","title":"programmers. 배달","tags":["Algorithms","Graph","Shortest Path","Dijkstra Algorithm"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\n## Greedy algorithm\n매 상황에서 최적의 해를 구하는 것이 전체 문제의 최적 해가 될때 사용하는 알고리즘으로, 구현하기는 어렵지 않지만 정당성을 증명해야 답을 보장할 수 있다. 다음의 문제들에서 그리디 알고리즘을 사용해 정당성 증명을 연습할 수 있다.\n\n> 모든 문제의 출처: [이코테 유튜브](https://www.youtube.com/watch?v=m-9pAwq1o3w&list=PLRx0vPvlEmdAghTr5mXQxGpHjWqSz0dgC&index=1)\n\n\n### <문제> 거스름 돈\n`n`원을 `10원`, `50원`, `100원`, `500원` 동전으로 거슬러 주려고 할 때, 거슬러주는 동전의 개수를 최소화하려고 한다. 이때 거슬러 주는 동전의 최소 개수를 반환하는 문제이다.\n\n#### 문제 해결 아이디어\n- 전략: 가장 큰 화폐 단위부터 거슬러 준다.\n- 정당성 증명: 거슬러 줄 동전 중 큰 단위가 항상 작은 단위의 배수이므로, 같은 돈을 거슬러 주는 방법 중 가장 적은 동전을 사용하는 방법은 가능한 한 가장 큰 단위의 동전을 사용하는 것이다.\n- 즉 동전의 단위가 500원, 400원, 100원으로 주어진 경우에는 그리디 알고리즘으로 해답을 구할 수 없다.\n\n#### 파이썬 코드\n```python\ncoins = [500, 100, 50, 10]\ncnt = 0\n\nfor coin in coins:\n\tcnt += n // coin\n\tn %= coin\n\nprint(count) \n```\n\n### <문제> 1이 될 때까지\n1이 아닌 숫자 `N`과 `K`가 주어진다. 오직 두 가지 연산만 할 수 있는데, N이 K로 나누어지는 경우 `N을 K로 나눌` 수 있고, 그 외의 경우에는 `N에서 1을 뺄` 수 있다. 여기서 N을 1로 만드는 최소 연산 횟수를 구하는 문제다.  \n\n#### 문제 해결 아이디어\n- 전략 : 숫자 N이 K로 나누어지는 경우의 수를 최대한으로 하되, 만약 N이 K로 나누어지지 않으면 1을 뺀다.\n- 정당성 증명: 만약 N이 K로 나누어지면, N과 K는 1이 아니므로 N 나누기 K 는 N - 1보다 작은 값이 된다. 언제나 1을 빼는 것으로 N을 1로 만들 수 있으므로, 매번 N을 최대한 작은 수로 만드는 방법으로 전체 연산 횟수를 최소화 할 수 있다.\n\n#### 파이썬 코드\n```python\nn, k = map(int, input().split())\ncnt = 0\n\nwhile n >= k:\n\tif n % k == 0:\n\t\tcnt += 1\n\t\tn //= k\n\telse:\n\t\tcnt += n % k\n\t\tn -= n % k\n\nprint(cnt + n - 1)\n```\n\n### <문제> 곱하기 혹은 더하기\n0 또는 양수인 임의의 수들 `s`가 주어질 때, 두 수를 더하거나 곱해서 만들 수 있는 가장 큰 수를 반환하는 문제다.\n\n#### 문제 해결 아이디어\n- 전략 : 피연산자 두개 중 하나라도 0이나 1이면 더하고, 그 외의 경우면 곱한다.\n- 정당성 증명: 연산의 왼쪽 숫자를 임의의 수 N이라 할 때, 모든 수는 0 또는 양수이므로 `N * 0 = 0` 보다 `N + 0 = N` 이 같거나 크고, `N * 1 = N` 보다 `N + 1` 이 더 크다. 반면, 2이상 9이하의 정수 X에 대해 `N * X` 보다 `N + X` 가 같거나 작다.\n- 곱셈과 덧셈은 교환법칙이 성립하므로 피연산자의 순서에 관계없이 위의 법칙이 성립한다.\n\n#### 파이썬 코드\n```python\ns = input()\nret = int(s[0])\n\nfor i in range(1, len(s)):\n\tnum = int(s[i])\n\tif num <= 1 or ret <= 1: \n\t\tret += num\n\telse:\n\t\tret *= num\n\nprint(ret)\n```\n\n### <문제> 모험가 길드\n어떤 마을에 모험가들이 있다. 모험가들은 제각기 공포도가 있는데, 공포도가 `i`인 사람은 `i`명 이상이 속한 그룹에 들어야 모험을 나갈 수 있다. 모험가들의 공포도가 주어질 때, 모험을 나가는 그룹의 수를 최대화해서 반환하는 문제다. 단, 모험가들이 마을에 남아있는 경우도 허용된다.\n\n#### 문제 해결 아이디어\n- 전략: 공포도가 적은 사람부터 순서대로 그룹을 꾸리되, 그룹의 최소 정원이 만족되면 다음 그룹으로 편성한다.\n- 정당성 증명: 주어진 정보에 대해 그룹수가 최대가 되도록 꾸려진 임의의 편성이 있다고 하자. 이 편성의 한 그룹에 대해  공포도가 적은 사람부터 그룹의 최소 정원을 만족하도록 그룹을 만들고 이외의 모험가들을 제외시켜도 여전히 그룹의 수는 최대이다. 따라서 위의 전략은 최적의 해를 보장한다.\n\n#### 파이썬 코드\n```python\nn = int(input())\nfears = list(map(int, input().split()))\nfears.sort()\n\n# cnt : 각 그룹에 포함된 사람의 수\n# ret : 전체 그룹의 수\ncnt, ret = 0, 0\n\nfor fear in fears:\n\tcnt += 1\n\t# fear가 cnt를 넘으면,\n\t# 전체 그룹 수를 1 증가하고 cnt를 초기화 한다. \n\tif cnt >= fear:\n\t\tret += 1\n\t\tcnt = 0\n\t\nprint(ret)\n```\n\n","excerpt":"Greedy algorithm 매 상황에서 최적의 해를 구하는 것이 전체 문제의 최적 해가 될때 사용하는 알고리즘으로, 구현하기는 어렵지 않지만 정당성을 증명해야 답을 보장할 수 있다. 다음의 문제들에서 그리디 알고리즘을 사용해 정당성 증명을 연습할…","fields":{"slug":"/greedy_algorithm/"},"frontmatter":{"date":"Mar 09, 2022","title":"그리디 알고리즘의 정당성 증명","tags":["Algorithm","Greedy Algorithm"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\n> 문제 : [프로그래머스](https://programmers.co.kr/learn/courses/30/lessons/72412)\n\n## 문제 해결 아이디어\n효율성 통과가 까다롭다고 느꼈던 문제중 하나로, 점수를 제외한 `검색 조건의 개수`가 `4개`에 불과하다는 점을 이용해서 모든 조건 조합을 해시한 다음 이진 검색을 통해 해결할 수 있었다.\n\n코드는 문제에서 요구하는 순서대로 작성하면 된다. 우선 `info`에서 주어진 정보로 `점수를 제외한 조건`들을 해시의 키로, `점수 조건`을 해시값으로 저장한다. 이때, 점수를 제외한 조건들을 모두 `'-'`로 대체하는 경우도 고려하도록 한다. 이때 파이썬 `combinations`를 이용해 모든 조합을 구했다. 그 다음 해시값인 리스트를 정렬하고, `query`에 주어진 `점수를 제외한 조건`을 해시에서 참조해서 주어진 `점수 조건`과 같거나 큰 값들 중 최소값을 구한다. 전체 길이에서 최소값의 인덱스를 빼서 반환하면 된다.\n\n### 시간 복잡도 계산하기\n문제가 되는 것은 시간 복잡도이다. 우선 주어진 `info`배열의 크기가 최대 `50,000`이므로, 점수를 제외한 모든 조건 조합을 해시하는 경우 해시의 키가 형성되는 횟수를 세어야 한다. 모든 조건에서 `'-'`가 대신 들어가는 경우를 고려해도 $\\sum^{4}_{i=0} \\binom{4}{i}$개로, 이 값은 상수이므로 선형시간안에 해결할 수 있다. \n해시값을 정렬 하는데에는 $O(NlogN)$ 시간이 소요된다. 마지막 과정인 `query`에 대해서도 `for문`을 거쳐야하고, `query`가 최대 `100,000`개 이므로 효율적인 탐색이 필요하다. 이진탐색을 활용하면 $O(NlogN)$ 시간 복잡도로 문제를 해결할 수 있다. \n\n전체 과정의 시간 복잡도는 $O(N) + O(NlogN) + O(NlogN) = O(NlogN)$이 된다.\n\n\n## 파이썬 코드\n```python\nfrom itertools import combinations\n\ndef solution(info, query):\n\n    hsh = {}\n    for inf in info:\n        # info의 값 중 조건 분류와 점수를 따로 저장한다. \n        conds = inf.split()[:-1]\n        score = int(inf.split()[-1])\n        \n        # 모든 조건의 조합을 해시한다. \n        for i in range(5):\n            combs = list(combinations(range(4), i))\n            for comb in combs:\n                # 순서대로 '-'를 삽입하는 키를 생성한다.\n                temp = conds.copy()\n                for j in comb:\n                    temp[j] = '-'\n                new_cond = ' and '.join(temp)\n                \n                # hsh의 조건 조합 키에 점수을 추가한다.\n                if new_cond not in hsh:\n                    hsh[new_cond] = [score]\n                else:\n                    hsh[new_cond] += [score]\n\n    # 이진 검색을 위해 hsh값 리스트 내의 값들을 정렬한다.  \n    for values in hsh.values():\n        values.sort()\n    \n    ret = []   \n    for q in query:\n        # query의 값 중 조건 분류와 점수를 따로 저장한다.\n        cond = ' '.join(q.split()[:-1])\n        score = int(q.split()[-1])\n        \n        # hsh에 해당하는 키가 있는 경우\n        if cond in hsh:\n            # hsh의 값에서 점수가 query에서 요구하는 점수 \n            # score와 같거나 큰 점수를 이진 탐색한다.\n            left, right = 0, len(hsh[cond])\n            while left <= right and left != len(hsh[cond]):\n                half = (left + right) // 2\n                if hsh[cond][half] >= score:\n                    right = half - 1\n                else:\n                    left = half + 1\n            # 해시값 길이에서 leftmost 인덱스를 뺀 값을 저장한다.\n            ret.append(len(hsh[cond]) - left)\n        # 만약 hsh에 해당 키가 없는 경우, 0을 저장한다.\n        else:\n            ret.append(0)\n\n    return ret\n```","excerpt":"문제 : 프로그래머스 문제 해결 아이디어 효율성 통과가 까다롭다고 느꼈던 문제중 하나로, 점수를 제외한 가 에 불과하다는 점을 이용해서 모든 조건 조합을 해시한 다음 이진 검색을 통해 해결할 수 있었다. 코드는 문제에서 요구하는 순서대로 작성하면 된…","fields":{"slug":"/programmers. 순위 검색/"},"frontmatter":{"date":"Mar 05, 2022","title":"programmers. 순위 검색","tags":["Algorithms","programmers","Hashing","Binary Search"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\n> 문제 : [프로그래머스](https://programmers.co.kr/learn/courses/30/lessons/43163)\n\n\n## 문제 해결 아이디어\n\n단어가 알파벳 하나 차이로 다른 경우 단어 노드를 간선으로 연결한 후 시작 단어에서 타깃 단어에 이르기 까지 깊이 우선 탐색을 이용하여 해결할 수 있다.\n\n- 그래프 생성: 단어 2개 조합에서 알파벳이 하나 차이나는 단어를 그래프에 저장한다.\n- 최소 변환 횟수 찾기: 깊이 우선 탐색을 이용해, 타겟 단어에 이르기까지 최소 거리를 업데이트하며 연결된 노드를 탐색한다.\n\n\n## 파이썬 코드\n```python\nfrom collections import defaultdict\nfrom itertools import combinations\n\ndef solution(begin, target, words):\n    \n    graph = defaultdict(list)\n    combs = list(combinations(words + [begin], 2))\n    \n    # 2개 단어 조합 중에서 알파벳이 하나 차이나면 graph에 저장\n    for comb in combs:\n        w1, w2 = comb[0], comb[1]\n        sameness = sum([1 if c1 == c2 else 0 for c1, c2 in zip(w1, w2)])\n        if sameness == len(w1) - 1:\n            graph[w1].append(w2)\n            graph[w2].append(w1)\n        \n    # 깊이 우선 탐색 구현\n    min_d = 100\n    visited = []\n    # stack에 [노드, begin에서의 거리] 형태로 저장\n    stack = [[begin, 0]]\n    while stack:\n        v, d = stack.pop()\n        if v == target and min_d > d:\n            min_d = d\n        if v not in visited:\n            visited.append(v)\n            for u in graph[v]:\n                stack.append([u, d + 1])\n    \n    return min_d if min_d != 100 else 0\n```","excerpt":"문제 : 프로그래머스 문제 해결 아이디어 단어가 알파벳 하나 차이로 다른 경우 단어 노드를 간선으로 연결한 후 시작 단어에서 타깃 단어에 이르기 까지 깊이 우선 탐색을 이용하여 해결할 수 있다. 그래프 생성: 단어 2개 조합에서 알파벳이 하나 차이나…","fields":{"slug":"/programmers. 단어 변환/"},"frontmatter":{"date":"Feb 26, 2022","title":"programmers. 단어 변환","tags":["Algorithms","programmers","Graph","DFS"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\n> 문제 : [프로그래머스](https://programmers.co.kr/learn/courses/30/lessons/42627)\n\n## 문제 해결 아이디어\n\n- 하드디스크가 비어있을 때 요청이 들어오면 바로 처리한다.\n- 하드디스크가 작업 중일 때 요청이 들어오면 진행 중인 작업을 끝내고, 작업 소요 시간을 최소 힙으로 정렬하여 힙의 순서대로 처리한다.\n\n이때 `start`와 `end`로 현재 작업 시간의 양쪽 끝을 설정해서 지속적으로 업데이트 할 수 있다. 또 루프를 시작할 때 요청시간이 `end`와 작거나 같은 것으로 탐색하므로, 아무 것도 처리하지 않는 빈 시간에 대해 주어진 리스트 `jobs`의 인덱스 `i`는 그대로 두고 `end`를 1씩 증가시킨다. \n\n`jobs`의 길이, 즉 힙이 정렬할 원소 개수의 최대값은 500 이하이고, 작업 소요시간은 1,000이하이지만 다음코드에서 한번에 처리(`end += now[0]`)하므로 시간내에 문제를 해결할 수 있다.\n\n## 파이썬 코드\n```python\nfrom heapq import heappush, heappop\n\ndef solution(jobs):\n\n    start, end = -1, 0\n    ret, hq = [], []\n\n    i = 0\n    # 힙에서 하나를 꺼낼때 마다 start와 end를 업데이트한다\n    while i < len(jobs):\n        # 요청시간이 작업 도중인 경우, 힙에 추가하기\n        for job in jobs:\n            if start < job[0] <= end:\n                heappush(hq, [job[1], job[0]])\n        # 힙이 비어 있지 않으면\n        # 힙에 있는 소요 시간이 가장 작은 작업을 처리한다\n        if len(hq) > 0:\n            now = heappop(hq)\n            start = end\n            end += now[0]\n            ret.append(end - now[1])\n            i += 1\n        # 힙이 비었으면, 즉 현재 작업이 끝날 때까지 요청이 없으면\n        # 요청이 들어올 때까지 end를 증가시킨다\n        else:\n            end += 1\n\n    # 문제에서 요구하는 작업 소요시간 평균을 반환한다\n    return sum(ret) // len(ret)\n```","excerpt":"문제 : 프로그래머스 문제 해결 아이디어 하드디스크가 비어있을 때 요청이 들어오면 바로 처리한다. 하드디스크가 작업 중일 때 요청이 들어오면 진행 중인 작업을 끝내고, 작업 소요 시간을 최소 힙으로 정렬하여 힙의 순서대로 처리한다. 이때 와 로 현재…","fields":{"slug":"/programmers. 디스크 컨트롤러/"},"frontmatter":{"date":"Feb 26, 2022","title":"programmers. 디스크 컨트롤러","tags":["Algorithms","programmers","Heap"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\n> 문제 : [프로그래머스](https://programmers.co.kr/learn/courses/30/lessons/12927)\n\n## 문제 해결 아이디어\n문제에서 정의한 야근 피로도는 야근을 시작한 시점에서 남은 일의 작업량을 모두 제곱하여 더한 값으로 해석할 수 있다. 수식으로 쓰면 문제의 목표는\n$$\nmin(\\sigma_i {work_i}^2) \n$$\n이고 주어진 리스트에 대해 최대값을 최소화해서 목표를 달성할 수 있다. (남은 작업량이 주어지고 그 중에서 1만 처리할 수 있을때, 가장 큰 값을 1 처리하는 것이 전체 식을 최소화한다는 것을 증명할 수 있다.) 따라서 임의 시점에서 가장 작업량이 큰 일을 1만큼 처리해야 하며, 작업량을 최대힙으로 정렬해서 과제를 수행할 수 있다.\n\nn은 1,000,000 이하의 자연수이고 최대 $2*n$번 힙 연산이 수행되므로 $O(nlogn)$ 시간 내에 문제를 해결할 수 있다.\n\n## 파이썬 코드\n```python\nimport heapq\n\ndef solution(n, works):\n    if sum(works) <= n: return 0\n    \n    yageun = []\n    for work in works:\n        heapq.heappush(yageun, -work)\n        \n    # 한 시간 씩 작업하되, 가장 작업량이 큰 일을 1만큼 처리한다\n    while n != 0:\n        work = heapq.heappop(yageun)\n        heapq.heappush(yageun, work + 1)\n        n -= 1\n        \n    # 힙에 남은 원소에 대해 야근 피로도를 계산한다\n    return sum(list(map(lambda x: x ** 2, yageun)))\n```","excerpt":"문제 : 프로그래머스 문제 해결 아이디어 문제에서 정의한 야근 피로도는 야근을 시작한 시점에서 남은 일의 작업량을 모두 제곱하여 더한 값으로 해석할 수 있다. 수식으로 쓰면 문제의 목표는 이고 주어진 리스트에 대해 최대값을 최소화해서 목표를 달성할 …","fields":{"slug":"/programmers. 야근 지수/"},"frontmatter":{"date":"Feb 26, 2022","title":"programmers. 야근 지수","tags":["Algorithms","programmers","Heap"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\n> 문제 : [프로그래머스](https://programmers.co.kr/learn/courses/30/lessons/42628)\n\n## 문제 해결 아이디어\n\n최소 힙과 최대 힙을 동시에 이용하는 것이 핵심이다. 이중 우선순위 큐에 적용하는 세가지 연산을 경우 별로 나누어 고려한다.\n\n- 원소를 추가할 경우, 최소 힙과 최대 힙에 모두 추가한다.\n- 최소값을 제거할 경우, 최소 힙이 비어있지 않으면 최소힙의 최소값을 제거한다. 만약 최대힙의 인덱스 0인 값이 지우려는 해당 원소이면, 최대힙에서 이 원소를 제거한다.\n- 최대값을 제거할 경우, 최대 힙이 비어있지 않으면 최대힙의 최대값을 제거한다. 만약 최소힙의 인덱스 0인 값이 지우려는 해당 원소이면, 최소힙에서 이 원소를 제거한다.\n- 다음 루프를 실행하기 전에, 최소 힙이나 최대 힙 중 하나라도 비어있거나 최소힙의 최소값이 최대힙의 최대값보다 크면, 두개 힙을 모두 비운다.\n\n루프가 종료된 후, 최소힙과 최대힙 둘 중 하나라도 비어있으면 이중 우선순위 큐가 비었다는 뜻이므로 [0,0]을 반환한다. 아닐경우, 최대힙에서 최대값을 최소힙에서 최소값을 반환한다.\n\n주어진 리스트 operations의 길이는 최대 1,000,000이지만, 힙으로 정렬한 수행시간은 $O(NlogN)$으로 시간내에 해결 할 수 있다.\n\n\n## 파이썬 코드\n```python\nfrom heapq import heappush, heappop\n\ndef solution(operations):\n    \n    hq1, hq2 = [], []\n    for op in operations:\n        # hq1이 최소 힙, hq2가 최대 힙\n        if op[0] == 'I':\n            heappush(hq1, int(op.split()[-1]))\n            heappush(hq2, -int(op.split()[-1]))\n        \n        # 최대 힙에서 원소를 제거한다\n        # 최소 힙이 비지 않고, 삭제할 값이 최소 힙에 있으면, 최소 힙에서 원소를 제거한다\n        elif op == 'D 1' and hq2 != []:\n            if hq1 and hq1[0] == -hq2[0]:\n                heappop(hq1)\n            heappop(hq2)\n\n        # 최소 힙에서 원소를 제거한다\n        # 최대 힙이 비지 않고, 삭제할 값이 최대 힙에 있으면, 최대 힙에서 원소를 제거한다\n        elif op == 'D -1' and hq1 != []:\n            if hq2 and hq1[0] == -hq2[0]:\n                heappop(hq2)\n            heappop(hq1)\n\n        # 최소 힙이나 최대 힙 중 하나라도 비어있거나, 두 힙의 최소값이 최대값보다 크다면 \n        # 힙을 모두 비운다\n        if (not hq1 or not hq2) or (hq1[0] > -hq2[0]): \n            hq1, hq2 = [], []\n            \n    if not hq1 or not hq2: \n        return [0, 0]\n\n    return [-hq2[0], hq1[0]]\n```","excerpt":"문제 : 프로그래머스 문제 해결 아이디어 최소 힙과 최대 힙을 동시에 이용하는 것이 핵심이다. 이중 우선순위 큐에 적용하는 세가지 연산을 경우 별로 나누어 고려한다. 원소를 추가할 경우, 최소 힙과 최대 힙에 모두 추가한다. 최소값을 제거할 경우, …","fields":{"slug":"/programmers. 이중 우선순위 큐/"},"frontmatter":{"date":"Feb 26, 2022","title":"programmers. 이중 우선순위 큐","tags":["Algorithms","programmers","Heap"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\n`word2vec`은 2013년 구글에서 고안한 자연어 처리 아이디어로, 이에 기반한 모델은 `Continuous Bag-of-Words(CBOW)`와 `Skip-gram` 두가지가 있다. 이 글은 그 중에서 `CBOW` 모델을 원 논문과 deeplearning.ai 수업을 참고하여 정리한 글이다. \n\n**원 논문**:\n- Mikolov et. al., 2013, Efficient Estimation of Word Representations in Vector Space ([arxiv](https://arxiv.org/pdf/1301.3781.pdf))\n- Mikolov et. al., 2013, Distributed Representations of Words and Phrases and their Compositionality ([arxiv](https://proceedings.neurips.cc/paper/2013/file/9aa42b31882ec039965f3c4923ce901b-Paper.pdf))\n\n\n## 0. CBOW란\nCBOW(Continuous Bag-of-Words, 연속되는 단어 주머니)는 \n- 텍스트 데이터를 벡터 공간에 표현하는 `단어 임베딩(word embedding)` 모델이자,  \n- `얕은 신경망(neural network)` 모델이며, \n- 스스로 훈련 데이터를 생성하는 `자기 지도 훈련(self-supervised learning)` 모델이다. \n\nCBOW 모델이 처음 소개될 때는 50-100 차원의 원 핫 벡터로 몇 백만개의 단어를 훈련시켰다. \n\n\n### 📖 Skip-gram과의 차이점\nCBOW 모델은 여러개의 단어 데이터를 입력하면 그에 상응하는 한개의 단어를 출력하는 `Many to One` (여러개 데이터를 입력받아 한개의 데이터를 출력하는 모델 구조) 모델이다. 반면 Skip-gram은 한개의 단어를 입력했을 때 그에 대응하는 여러개의 단어를 출력하는 `One to Many` 모델이다. 즉 두 모델의 구조는 `반전`되어있고, 입력값과 출력값이 서로 반대된다. \n\n## 1. 모델의 구조\nCBOW는 얕은 신경망 모델로, 이 글에서는 한 개의 은닉층(hidden layer)를 가지는 신경망 모델을 고려한다.\n\n![](cbow_model_architecture.png)\n*image by DeepLearning.AI*\n\n모델의 흐름은 다음과 같다.\n1. 텍스트 데이터를 원 핫 벡터로 변환한다.\n2. 첫번째 은닉층(hidden layer)을 거친다.\n    - 활성화 함수 : ReLU\n3. 두번째 결과층(output layer)을 거친다.\n    - 활성화 함수 : Softmax\n4. 결과 벡터의 값 중 가장 큰 값으로 예측한다.\n\n모델을 이해하고 실제로 구현하기 위해서는 각 층의 차원을 정확히 알아야 한다.\n### 📖 벡터의 차원\n변수를 다음과 같이 정의할 때,\n- $V$ : 단어 사전의 크기,  혹은 원-핫 벡터의 크기.\n- $N$ : 임베딩 크기. 모델의 하이퍼파라미터이다.\n- $m$ : 배치 크기. 한번에 훈련할 데이터의 개수이다.\n\n입력값 $X$의 차원\n$$\nX \\in M(V, m)\n$$\n에 대해 각 층에 대한 벡터의 차원을 다음과 같이 정리할 수 있다.\n<center>\n\n|은닉층 벡터|차원|결과층 벡터|차원|\n|---|---|---|---|\n|$W_1$|$(N, V)$|$W_2$|$(V, N)$|\n|$B_1$|$(N, m)$|$B_2$|$(V, m)$|\n|$z_1$|$(N, m)$|$z_2$|$(V, m)$|\n|$relu(z_1)$|$(N, m)$|$softmax(z_2)$|$(V, m)$|\n</center>\n\n$softmax(z_2) \\equiv \\hat{Y}$ 이므로 예측값이 입력값과 같은 차원을 가지는 것을 알 수 있다. 즉 모델이 반환하는 벡터의 열 벡터는 입력 열 벡터와 순서가 같은 원 핫 벡터이다.\n\n## 2. 모델의 전처리\n\nCBOW 모델로 문장의 빈칸을 주위 단어에 기반해 예측하는 과제를 수행해보자. 다음 문장의 빈칸에 뭐가 들어갈까?\n\n\"npm은 Node.js의 ____ 관리를 위한 패키지 매니저이다.\"\n\nCBOW 모델을 구현하기 위해서는 텍스트 데이터를 토큰화 한 후, 데이터를 모델에 입력하는 형태로 변환하는 다음 작업이 필요하다.\n\n### 📖  중심어(center word)와 맥락 단어들(context words)\n자기 지도 학습은 사람이 라벨링을 할 필요가 없다는 장점이 있다. 그러기 위해서는 가공되지 않은 텍스트 데이터에서 훈련 데이터($X$, 입력 데이터)와 훈련 타겟($Y$, 참값)을 구분해서 자료화할 필요가 있다. \n\nCBOW 모델에서 예측할 대상(target)인 문장의 빈칸을 `중심어`로, 이 단어와 문장 내에서 인접한 단어를 `맥락 단어`로 이름지을 수 있다. `맥락 단어`는 중심어로 부터 거리 $C$ 만큼 떨어져 있는 인접한 단어들로 정의하며, $C$를 `맥락의 절반 크기(context half-size)`라고 하자. $C$는 모델의 성능을 좌우하는 하이퍼파라미터 중 하나이다. 왼쪽 맥락 단어 리스트와 중심어, 오른쪽 맥락 리스트의 크기를 모두 더한 값을 `윈도우`라고 일컫는다. \n\n예를 들면, 문장 한개로 구성된 데이터에 대해 다음과 같이 이해할 수 있다. \n```python\n# given tokenized data and context half-size, \n# returns center word and list of context words \ndef center_and_context_word(data, C):\n    for i in range(C, len(data)-C):\n        center_word = data[i]\n        context_words = []\n        for j in range(i-C, i+C+1):\n            if j != i:\n                context_words.append(data[j])\n        yield center_word, context_words\n\nC = 2 # context half-size\ndata = [\"npm은\", \"Node.js의\", \"패키지\", \"관리를\", \"위한\", \"패키지\", \"매니저이다\", \".\"]\n\ncenter_word, context_word = next(center_and_context_word(data, C))\n\nprint(center_word) # \"패키지\"\nprint(context_word) # [\"npm은\", \"Node.js의\", \"관리를\", \"위한\"]\nprint(len(context_word + center_word)) # 5, window\n``` \n모델의 입력값은 `맥락 단어 벡터들의 평균값`을 취한다. 사실 CBOW 모델 이름에 Bag이 들어가는 이유는 $C$의 범위 내에 있는 맥락 단어들이 문장에서의 순서에 관계없이 여겨지기 때문이고, 이 특징은 이후에 등장하는 Sequential 모델과 구분되는 차이점이다.\n\n\n## 3. 모델 훈련하기\n\nCBOW 모델은 신경망 모델이므로 일반적인 forward propagation, backward propagation, gradient descent 과정을 거친다. 세가지 과정을 `keras` 라이브러리에서 `Layer` 객체로 비교적 간단하게 구현할 수 있다.\n\n\n### 📂 Keras로 CBOW 구현하기\n```python\nfrom tf.keras import layers\n\n# Input size: (batch_size, vocab_size)\ncbow_model = tf.keras.Sequential{\n    # 원 핫 벡터의 배치를 임베드한다\n    input_layer = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim), \n    # relu 은닉층으로 비용이 음수값을 가지지 않게 한다\n    hidden_layer = layers.Dense(units=embed_dim,activation='relu'), \n    # 원 핫 벡터의 배치를 확률로 출력한다\n    output_layer = layers.Dense(input_dim=vocab_size, activation='softmax')\n}\n\nbatch_size = 256\nepochs = 10\n\ncbow_model.compile(\n    optimizer='Adam', \n    loss=tf.keras.losses.CategoricalCrossentropy()\n)\n\ncbow_model.fit(\n    train_data, train_target, \n    batch_size=batch_size, epochs=epochs\n)\n```\n\n## 4. 단어 임베딩 추출하기\n\n단어 임베딩은 원 핫 벡터에 비해 `밀도가 높은(Dense) 벡터`로, 단어 임베딩에는 여러가지 이점이 있다. 첫째로 단어 임베딩 벡터간의 거리를 비교해서 의미론적(semantic)이고 문법론적인(syntactic) 정보를 얻을 수 있다. 둘째로 차원을 작게 만드는 것, 즉 `차원 축소(Dimensionality Reduction)`를 통해 계산 횟수를 획기적으로 줄일 수 있다. 벡터의 밀도가 높다는 것은 같은 데이터를 상대적으로 작은 차원으로 표현하는 것을 뜻한다. 반면에 벡터의 차원이 증가함에 따라 벡터를 계산하는 횟수는 기하급수적으로 늘어나게 되는데, 이 현상을 `차원의 저주(the curse of dimensionality)`라고 한다. 그 중에서 2차원이나 3차원 벡터는 시각화가 가능하므로 직관적인 이해에 도움이 된다.\n\n단어 임베딩은 CBOW 모델의 부산물이라고 할 수 있는데, 단어 임베딩은 훈련이 끝난 후 그 결과인 가중치 벡터로 부터 얻을 수 있다.\n\n단어 임베딩으로 선택할 수 있는 `옵션`은 다음과 같다.\n- 첫번째 가중치 벡터 $W_1$ 의 열(column) 벡터\n- 두번째 가중치 벡터 $W_2$ 의 행(row) 벡터\n- 두 가중치 벡터의 평균 $1/2 *(W_1 + W_2^{T})$ 의 열 벡터\n\n마지막 경우는 $1/2 * (W_1^{T} + W_2)$의 행 벡터와 같다. 위의 모든 경우에 대해 `한개의 단어 임베딩 벡터의 크기`는 임베딩 크기 $N$에 대해 $(N,1)$ 또는 $(1, N)$인 것을 알 수 있다.\n\n## 5. 모델 평가하기\n모델을 평가하는 방법에는 크게 두가지가 있다.\n### 📖  내재적 평가와 외재적 평가\n내재적 평가(Intrinsic Evaluation)는 임베딩된 단어들의 의미론적이고 문법론적인 관계를 평가하는 방법이다. 유의어(Analogies) 평가나 클러스터링 알고리즘, 또는 PCA 같은 시각화 기법들이 내재적 평가에 포함된다. 반면 외재적 평가(Extrinsic Evaluation)는 모델의 전체적인 성능을 파악하는데에 사용되는 방법이다. 전체 모델을 평가할 수 있지만, 평가 시간이 오래 걸리며 개선 방법에 대한 직관을 얻기 어렵다는 단점이 있다.\n\n### 📂  테스트 셋에 대해 (내재적으로) 평가하기\n![](Semantic-Syntactic_Word_Relationship_test_set.png)\n*table from Mikolov et al., 2013, Efficient Estimation of Word Representations in Vector Space*\n\n위의 표는 4개의 모델을 두가지 훈련 데이터에 대해 평가한 결과이다. 첫번째 훈련 데이터는 `의미론적(semantic)`이고 `문법론적(syntactic)` 관계 정확도인데, CBOW가 의미론적 정확도는 Skip-gram보다 두배 이상 떨어지지만 문법적 정확도에서는 조금 더 나은 것을 알 수 있다. 그렇지만 의미론적 정확도에 비해 문법론적 정확도에서 평가 모델들의 편차가 더 적었다. 두번째 데이터 셋에 대해서는 CBOW가 Skip-gram보다 단어 관계 평가가 조금 더 나은 것을 볼 수 있다.\n\n_참고 : 논문에서는 1억개가 넘어가지 않는 vocab에 대해 CBOW 모델을 훈련했으며, $C=4$ 설정에서 log-linear 분류로 최적의 결과를 얻었다고 한다._\n\n## 나가며\n지금 2022년에는 산업에서 거의 사용되지 않는 CBOW 모델이지만 모델의 구조를 설계하는 아이디어를 볼수있는 좋은 실습이었다.\n\n## 출처\n1. Mikolov et al., 2013, Efficient Estimation of Word Representations in Vector Space\n2. Coursera, deeplearning.ai, NLP Specialization, Course 2, Natural Language Processing with Probabilistic Models","excerpt":"은 2013년 구글에서 고안한 자연어 처리 아이디어로, 이에 기반한 모델은 와  두가지가 있다. 이 글은 그 중에서  모델을 원 논문과 deeplearning.ai 수업을 참고하여 정리한 글이다.  원 논문: Mikolov et. al., 2013,…","fields":{"slug":"/word2vec_cbow/"},"frontmatter":{"date":"Feb 25, 2022","title":"word2vec - Continuous Bag-of-Words(CBOW)","tags":["NLP","word2vec","Word Embedding"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\n> 문제 : [프로그래머스](https://programmers.co.kr/learn/courses/30/lessons/42861)\n\n\n### 문제 해결 아이디어\n`두 지점 사이`에 대해 건설 비용이 작은 것부터 건설하면 전체 건설 비용이 가장 작도록 선택할 수 있다. 만약 두 지점 사이의 건설 비용이 아니라 부분 그래프의 건설 비용이 주어졌다면 그리디 알고리즘으로 구현할 수 없다.\n\n#### 그리디 알고리즘 구현:\n- 건설 비용을 최소화 하는 것이 목적이므로 건설 비용이 저렴한 다리 부터 차례대로 건설한다.\n- 단, 다리의 양쪽 지점이 이미 연결된 경우에는 고려하지 않는다.\n- 모든 섬이 연결될 때까지 다리를 추가한다.\n\n\n그래프의 모든 노드에 대해 추가한 경로에 속하는 노드가 연결되어 있는지 확인하기 위해 깊이 우선 탐색을 구한현다.\n\n\n### 파이썬 코드\n```python\nfrom collections import defaultdict\n\ndef solution(n, costs):\n    cost = 0\n    nodes = list(range(n))\n    graph = defaultdict(list)\n    # 건설 비용이 저렴한 순으로 다리를 정렬한다.\n    costs.sort(key=lambda x: x[2])\n    \n    for i in range(len(costs)):\n        # 다리의 양쪽 지점이 이미 연결되어 있으면 고려하지 않는다.\n        node1, node2 = costs[i][:2]\n        if connected(node1, node2, graph):\n            continue\n            \n        # 양쪽 지점이 연결 되어 있지 않으면 다리를 건설한다.\n        cost += costs[i][2]\n        graph[node1].append(node2)\n        graph[node2].append(node1)\n        \n        # 모든 노드 node가 연결되어 있으면 멈춘다. \n        flag = True\n        for node in nodes:\n            if not connected(node1, node, graph):\n                flag = False\n        if flag:\n            break\n    return cost\n\n# graph에 있는 root와 target 노드의 연결 여부를 반환한다.\n# DFS(깊이 우선 탐색)으로 구현한다.\ndef connected(root, target, graph):\n    if root == target: \n        return True\n    visited = []\n    stack = [root]\n    while stack:\n        v = stack.pop()\n        if v == target: return True\n        if v not in visited:\n            visited.append(v)\n            for u in graph[v]:\n                stack.append(u)\n    return False\n```","excerpt":"문제 : 프로그래머스 문제 해결 아이디어 에 대해 건설 비용이 작은 것부터 건설하면 전체 건설 비용이 가장 작도록 선택할 수 있다. 만약 두 지점 사이의 건설 비용이 아니라 부분 그래프의 건설 비용이 주어졌다면 그리디 알고리즘으로 구현할 수 없다. …","fields":{"slug":"/programmers. 섬 연결하기/"},"frontmatter":{"date":"Feb 11, 2022","title":"programmers. 섬 연결하기","tags":["Algorithms","programmers","Greedy Algorithm","Graph","DFS"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\n\n> 문제 : [프로그래머스](https://programmers.co.kr/learn/courses/30/lessons/68646)\n\n\n### 문제 해결 아이디어\n- 투 포인터 알고리즘으로 문제를 해결 할 수 있다.\n\n1. 배열의 임의의 원소 a[i]에 대해 왼쪽 원소값 a[i-1]과 오른쪽 원소값 a[i+1]이 모두 a[i]보다 작은 경우 마지막까지 남을 수 없으므로 제외한다. \n2. 스택에 마지막까지 남을 원소값들을 저장한다. 오른쪽으로 한칸 나아갈 때 마다 스택에 저장한 원소와 배열 a의 남은 원소들에 대해 1번을 검사한다.\n3. 스택의 길이를 반환한다.\n\n\n### 파이썬 코드\n```python\ndef solution(a):\n\n    # 마지막까지 남는다고 판단한 풍선들의 값을 저장하는 스택\n    stack = [a[0]]\n    i = 1\n\n    while i < len(a) - 1:\n        # a[i] 값이 a[i-1]과 a[i-2]보다 크다면 마지막까지 남을 수 없다.\n        if stack[-1] < a[i] and a[i+1] < a[i]:\n            # 판단한 풍선들인 stack을 오른쪽부터 검사\n            while len(stack) > 1 and stack[-2] < stack[-1] and a[i+1] < stack[-1]:\n                stack.pop()\n        # 이외의 경우 마지막까지 남을 수 있으므로 stack에 저장\n        else:\n            stack.append(a[i])\n        # 한 칸 오른쪽 값들에 대해 검사\n        i += 1\n    \n    # 가장 오른쪽 풍선은 마지막까지 남는다.\n    if a[-1] != stack[-1]:\n        stack.append(a[-1])\n\n    return len(stack)\n```","excerpt":"문제 : 프로그래머스 문제 해결 아이디어 투 포인터 알고리즘으로 문제를 해결 할 수 있다. 배열의 임의의 원소 ai에 대해 왼쪽 원소값 ai-1과 오른쪽 원소값 ai+1이 모두 ai보다 작은 경우 마지막까지 남을 수 없으므로 제외한다.  스택에 마지…","fields":{"slug":"/programmers. 풍선 터뜨리기/"},"frontmatter":{"date":"Feb 11, 2022","title":"programmers. 풍선 터뜨리기","tags":["Algorithms","programmers","Two Pointer Algorithm"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\n\n> 문제 : [프로그래머스](https://programmers.co.kr/learn/courses/30/lessons/64062)\n\n\n### 문제 해결 아이디어\n- 문제는 k 길이의 구간(또는 window) 최대값 중 최소값을 구하는 문제로 이해될 수 있다.\n\n- stones 배열의 길이가 n이라 할 때, max()함수로 최대값을 구하는데에 선형 시간이 소요되므로 max()함수로 구현시 전체 시간 복잡도는 $O(k * (n - k))$ 이다. n과 k는 최대 20,000이므로 k가 10,000일 때 연산 횟수는 100,000,000회이기 때문에 이 방법으로는 시간내에 문제를 해결할 수 없다.\n\n- 구간의 최대값을 구할 때 k개의 구간이 중복되므로 최대 힙으로 이 문제를 해결할 수 있다. \n- $[0, k)$구간의 원소를 힙으로 정렬한 뒤, 다음 구간에 추가되는 원소를 하나씩 push하며, 매번 힙의 최대값을 업데이트 한다. 이때, 힙의 최대 원소의 인덱스가 구간 외이면 pop한다.\n\n- 힙에 n개의 원소를 한번 씩 push하고, 힙의 최대값이 구간 외일 때만 pop한다. 힙에는 최소 k개의 원소가 남아있어야 하기 때문에 pop은 최대 $n-k$번 일어나는데, 이 최악의 경우에 이전 원소들은 pop없이 push되었고, 이후 원소들도 힙의 길이 k에서 다시 시작하므로 선형시간을 넘지 않는다. 따라서 전체 수행시간은 $O(nlogn)$ 이다.\n\n\n### 파이썬 코드\n```python\nfrom heapq import heappush, heappop\n\ndef solution(stones, k):\n\n    # k가 전체 구간일 때 예외 처리\n    if len(stones) == k:\n        return max(stones)\n\n    # 최대 힙 구현\n    hq = []\n    for i in range(0, k):\n        heappush(hq, (-stones[i], i))\n    k_maxes = [-hq[0][0]] # k 길이 구간에서의 최대값 저장\n\n    # 힙에 원소를 하나씩 업데이트 하면서 \n    # 만약 힙의 최대값의 인덱스가 구간 안에 있지 않으면 힙에서 제거한다.\n    for i in range(k, len(stones)):\n        heappush(hq, (-stones[i], i))\n        while hq[0][1] <= i - k:\n            heappop(hq)\n        k_maxes.append(-hq[0][0])\n        \n    return min(k_maxes) # 저장된 구간 최대값들 중 최소값 반환\n```\n","excerpt":"문제 : 프로그래머스 문제 해결 아이디어 문제는 k 길이의 구간(또는 window) 최대값 중 최소값을 구하는 문제로 이해될 수 있다. stones 배열의 길이가 n이라 할 때, max()함수로 최대값을 구하는데에 선형 시간이 소요되므로 max()함…","fields":{"slug":"/programmers. 징검다리 건너기/"},"frontmatter":{"date":"Feb 10, 2022","title":"programmers. 징검다리 건너기","tags":["Algorithms","programmers","Heap"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\n\n> 문제 : [프로그래머스](https://programmers.co.kr/learn/courses/30/lessons/12905)\n\n\n### 문제 해결 아이디어\n보드의 가로 세로 길이가 최대 1,000이므로 모든 보드의 원소에 대해 구간별로 탐색하면 문제에서 요구하는 시간을 맞출 수 없다. 대신 보드의 원소가 모두 1 또는 0이라는 것을 이용하여 (길 찾기 예제에서 자주 구현하는 것처럼) 다이내믹 프로그래밍으로 문제를 해결할 수 있다. \n- `board`를 `오른쪽`과 `아래쪽`으로 탐색해가면서,\n- `board[i][j] = 1`인 지점에서 왼쪽으로 한칸, 위쪽으로 한칸, 그리고 대각선 왼쪽 위로 한칸 이동한 지점들의 값 중 최소인 값에 1을 더한 값을 저장한다.\n이때 임의의 x, y에 대해 board[x][y]는 왼쪽과 위쪽으로 인접해 있는 정사각형의 길이를 반영하게 되며 1을 더함으로서 board[i][j]의 길이를 반영할 수 있다.\n\n예를 들어 board가 가로 세로 2인 정사각형이고 board[1][1]=1인 경우, board[0][0], board[0][1] 그리고 board[1][0] 중 한 원소라도 0인 경우 board[1][1]=1이고 board의 가장 긴 정사각형의 길이는 1이다. 반면에 세 원소가 모두 1인 경우 board[1][1]=2로 최대 정사각형의 길이는 2다.\n\n이때, 행과 열의 첫번째 인덱스에 대해서는 계산하지 않으므로 예외처리에 신경쓴다.\n\n\n### 파이썬 코드\n```python\ndef solution(board):\n    \n    # board 가로 세로 길이가 1인 경우 예외 처리\n    if len(board) == 1 or len(board[0]) == 1:\n        if max(board) == 0:\n            return 0\n        else:\n            return 1\n        \n    answer = 0\n    for i in range(1, len(board)):\n        for j in range(1, len(board[0])):\n            # board[i][j] : 왼쪽과 위쪽의 board에 대해 인접한 정사각형의 최대 길이\n            # 더해지는 1은 board[i][j]를 포함해 더해지는 길이\n            if board[i][j] != 0:\n                board[i][j] = min(board[i-1][j], board[i][j-1], board[i-1][j-1]) + 1\n            answer = max(answer, board[i][j])\n\n    return answer ** 2\n````\n\n위의 방법으로 구현할 경우 이중 for문에 의해 수행시간은 $O(N^2)$이며, 따라서 보드의 가로 세로 길이가 1,000이더라도 시간 제한을 통과할 수 있다.\n\n\n","excerpt":"문제 : 프로그래머스 문제 해결 아이디어 보드의 가로 세로 길이가 최대 1,000이므로 모든 보드의 원소에 대해 구간별로 탐색하면 문제에서 요구하는 시간을 맞출 수 없다. 대신 보드의 원소가 모두 1 또는 0이라는 것을 이용하여 (길 찾기 예제에서 …","fields":{"slug":"/programmers. 가장 큰 정사각형 찾기/"},"frontmatter":{"date":"Feb 09, 2022","title":"programmers. 가장 큰 정사각형 찾기","tags":["Algorithms","programmers","Dynamic Programming"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\n\n> 문제 : [프로그래머스](https://programmers.co.kr/learn/courses/30/lessons/86052)\n\n\n### 문제 해결 아이디어\n구현 문제와 그래프 사이클에 대한 문제가 합쳐져 있다.\n\n1. 구현 문제는 빛을 좌회전, 우회전하는 것으로, `delta = [(-1,0), (0,1), (1,0), (0,-1)]`라고 했을 때 좌회전은 delta 배열에서 인덱스를 왼쪽으로 한 칸 옮기는 것으로, 우회전은 인덱스를 오른쪽으로 한 칸 옮기는 것으로 구현할 수 있다.\n\n2. grid의 세로길이 n, 가로 길이 m에 대해 모든 사이클 길이의 합은 $4 x n x m$이다. 즉 모든 가능한 이동에 대해 사이클이 성립한다.\n\n3. 격자에서 같은 노드라 하더라도 빛이 지나가는 방향이 다르면 다른 경로로 여겨진다. 따라서 모든 지점에 대해 오른쪽, 왼쪽, 위쪽, 아래쪽 **4개 경로**를 통해 빛이 **들어온** 경로를 기록한다(나간 경로를 기록할 수도 있다). 빛이 같은 경로로 지나간다면 같은 사이클이 되므로 중복해서 세지 않게 주의한다.\n\n종합해보면, 임의의 노드에 4개 방향으로 빛을 쏘되 해당 노드에 같은 방향으로 쏘아진 빛이 있는 경우는 제외한다. 같은 경로로 돌아올 때까지 경로를 이동하며 기록을 남기고, 사이클이 끝날 때 마다 사이클의 길이를 기록한다.\n\n2번에 의해 이중 for문 내의 연산은 모든 i of n, j of m에 대해 합해서 $4 * n * m$번이다. n과 m은 최대 500이므로 시간 제한을 통과할 수 있다.\n\n\n### 파이썬 코드\n```python\ndef solution(grid):\n\n    ret = []\n    n, m = len(grid), len(grid[0])\n    arr = [[[] for _ in range(m)] for _ in range(n)]\n    # 인덱스를 늘리면 오른쪽으로, 인덱스를 줄이면 왼쪽으로 이동하도록 배치\n    delta = [(-1,0), (0,1), (1,0), (0,-1)]\n\n    # 모든 노드에 대해 4가지 방향으로 들어오는 사이클 검토\n    for i in range(n):\n        for j in range(m):\n            for k in range(4):\n                # 해당 노드에 같은 방향으로 들어온 기록이 있으면 스킵\n                if k in arr[i][j]:\n                    continue\n\n                cnt = 0\n                x, y, d = i, j, k\n                dx, dy = delta[d]\n                # 해당 노드에 같은 방향으로 들어온 기록이 없을 때까지 경로 이동\n                while d not in arr[x][y]:\n                    arr[x][y].append(d)\n                    cnt += 1\n\n                    if grid[x][y] == 'L':\n                        dx, dy = delta[(d - 1) % 4]\n                    elif grid[x][y] == 'R':\n                        dx, dy = delta[(d + 1) % 4]\n\n                    x, y = (x + dx) % n, (y + dy) % m\n                    d = delta.index((dx, dy))\n                # 사이클의 길이를 저장\n                ret.append(cnt)\n    return sorted(ret)\n```\n\n\n\n","excerpt":"문제 : 프로그래머스 문제 해결 아이디어 구현 문제와 그래프 사이클에 대한 문제가 합쳐져 있다. 구현 문제는 빛을 좌회전, 우회전하는 것으로, 라고 했을 때 좌회전은 delta 배열에서 인덱스를 왼쪽으로 한 칸 옮기는 것으로, 우회전은 인덱스를 오른…","fields":{"slug":"/programmers. 빛의 경로 사이클/"},"frontmatter":{"date":"Feb 09, 2022","title":"programmers. 빛의 경로 사이클","tags":["Algorithms","programmers","Implementation","Graph","Cyclic Graph"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\n\n> 문제 : [프로그래머스](https://programmers.co.kr/learn/courses/30/lessons/42898)\n\n\n### 문제 해결 아이디어\n- 길 찾기 문제이며 다이나믹 프로그래밍으로 해결할 수 있다.\n- 오른쪽과 아래쪽으로만 갈 수 있으므로 왼쪽과 위쪽의 정보를 기반으로 해야한다. 최단 경로의 개수이므로 왼쪽과 위쪽의 값을 더하면 된다.\n- 배열 초기화를 0으로 했으므로, puddle에 대해서 -1로 기록해 두었다가 테이블을 채울때 마주치면 덧셈이 되지 않도록 0으로 바꿔둔다.\n- 수행시간은 이중 for문으로 $O(N^2)$이다.\n\n\n\n### 파이썬 코드\n```python\ndef solution(m, n, puddles):\n\n    # 행 n, 열 m 크기의 2차원 배열 생성\n    # road[i][j]는 (1,1)에서 (i,j)까지 갈 수 있는 최단 경로의 개수\n    road = [[0 for _ in range(m+1)] for _ in range(n+1)]\n    road[1][1] = 1\n    \n    # puddle로는 갈 수 없으므로 -1로 처리\n    for puddle in puddles:\n        y, x = puddle\n        road[x][y] = -1\n    \n    # road의 모든 지점을 탐색\n    for i in range(n):\n        for j in range(m):\n            # 시작 지점은 1로 고정\n            if i == j == 1:\n                continue\n            # 만양 puddle이면, 덧셈이 되지 않게 0으로 재처리\n            if road[i][j] == -1:\n                road[i][j] = 0\n                continue\n            # 왼쪽과 위쪽에서 올 수 있는 최단 경로의 개수의 합이 현재 지점의 최단 경로 개수\n            road[i][j] = (road[i-1][j] + road[i][j-1]) % 1000000007\n\n    return road[-1][-1]\n```","excerpt":"문제 : 프로그래머스 문제 해결 아이디어 길 찾기 문제이며 다이나믹 프로그래밍으로 해결할 수 있다. 오른쪽과 아래쪽으로만 갈 수 있으므로 왼쪽과 위쪽의 정보를 기반으로 해야한다. 최단 경로의 개수이므로 왼쪽과 위쪽의 값을 더하면 된다. 배열 초기화를…","fields":{"slug":"/programmers. 등굣길/"},"frontmatter":{"date":"Feb 09, 2022","title":"programmers. 등굣길","tags":["Algorithms","programmers","Dynamic Programming"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\n\n> 문제 : [프로그래머스](https://programmers.co.kr/learn/courses/30/lessons/43164)\n\n\n### 문제 해결 아이디어\n- 그래프에서 `주어진 부분 경로를 모두 사용하도록` 전체 경로를 만든다.\n- 현재 위치에서 출발하는 티켓이 있는 경우 스택에 저장하고 티켓을 사용 처리한다.\n- 현재 위치에서 출발하는 티켓이 없는 경우 해당 위치에는 도착만 가능하다. 해당 공항을 순서대로 방문 기록하면 가능한 방문 순서를 역순으로 뒤집어 저장하는 것이 된다.\n- 출발하는 티켓이 없는 경우부터 방문처리를 하므로, 기록한 순서를 역순으로 출력한다. \n\n\n### 파이썬 코드\n```python\ndef solution(tickets):\n\n    # 티켓의 경로 정보를 해시로 저장한다.\n    routes = {}\n    for t in tickets:\n        routes[t[0]] = routes.get(t[0], []) + [t[1]]\n    \n    # stack은 오른쪽에서부터 원소를 제거하므로\n    # 알파벳 순서가 앞서는 티켓을 먼저 선택하기 위해 역순으로 정렬한다.\n    for r in routes:\n        routes[r].sort(reverse=True)\n\n    # ICN에서 출발\n    stack = [\"ICN\"]\n    path = []\n    while len(stack) > 0:\n        now = stack[-1]\n        # 현재 위치 now에서 출발하는 티켓이 없으면 방문한다.\n        if now not in routes or len(routes[now]) == 0:\n            path.append(stack.pop())\n        # now에서 출발하는 티켓이 있으면 티켓의 도착지점을 stack에 저장한다.\n        else:\n            stack.append(routes[now].pop())\n\n    # path에 저장된 순서의 반대로 return한다.\n    return path[::-1]\n```","excerpt":"문제 : 프로그래머스 문제 해결 아이디어 그래프에서  전체 경로를 만든다. 현재 위치에서 출발하는 티켓이 있는 경우 스택에 저장하고 티켓을 사용 처리한다. 현재 위치에서 출발하는 티켓이 없는 경우 해당 위치에는 도착만 가능하다. 해당 공항을 순서대로…","fields":{"slug":"/programmers. 여행경로/"},"frontmatter":{"date":"Feb 09, 2022","title":"programmers. 여행경로","tags":["Algorithms","programmers","Graph"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\n\n> 문제 : [프로그래머스](https://programmers.co.kr/learn/courses/30/lessons/42895)\n\n\n### 문제 해결 아이디어\n- 다이내믹 프로그래밍을 활용하여 해결 할 수 있다. \n- 최대 8번까지 N의 횟수를 세어야 하므로, DP 테이블을 길이 8인 1차원 배열로 만든다.\n- DP 테이블 dp[i]에 N을 i번 이용해 만들 수 있는 수의 배열을 저장한다. dp테이블은 테이블 인덱스 i에 대해 N을 i번 반복하는 수로 초기화한다. \n- N을 사용하는 횟수의 최소값을 반환해야 하므로 dp를 작은 수 부터 채워나간다. dp[j]에 있는 원소에 대해 dp[i-j]에 있는 원소를 연산하므로, `dp[j] {사칙연산} dp[i-j]`는 N을 총 $j + (i - j) = i$번 사용한다.\n\n\n\n#### 파이썬 코드\n```python\ndef solution(N, number):\n    \n    # dp[i] : N을 i번 이용해 만들 수 있는 수의 배열\n    # 초기값은 N을 i번 사용한 수로 정의한다.\n    dp = [[]] + [[int(str(N) * i)] for i in range(1, 9)]\n\n    if [number] in dp:\n      return dp.index([number])\n\n    # dp[j] {사칙연산} dp[i-j]는 N을 총 i번 사용한다.\n    for i in range(2, 9):\n        for j in range(1, i):\n          for a in dp[j]:\n            for b in dp[i-j]:\n                dp[i].append(a + b)\n                dp[i].append(a - b)\n                dp[i].append(a * b)\n                if b != 0: # 0으로 나누지 않도록 한다.\n                    dp[i].append(a // b)\n        # 탐색 시간을 줄이기 위해 중복 제거한다.\n        dp[i] = list(set(dp[i]))\n        if number in dp[i]:\n            return i\n\n    return -1\n```\n","excerpt":"문제 : 프로그래머스 문제 해결 아이디어 다이내믹 프로그래밍을 활용하여 해결 할 수 있다.  최대 8번까지 N의 횟수를 세어야 하므로, DP 테이블을 길이 8인 1차원 배열로 만든다. DP 테이블 dpi에 N을 i번 이용해 만들 수 있는 수의 배열을…","fields":{"slug":"/programmers. N으로 표현/"},"frontmatter":{"date":"Feb 09, 2022","title":"programmers. N으로 표현","tags":["Algorithms","programmers","Dynamic Programming"],"update":"Jan 01, 0001"}}},{"node":{"rawMarkdownBody":"\n분산 버전 관리 시스템인 깃 명령어(git commands)를 쉽게 볼 수 있도록 정리한 문서입니다.\n\n\n## 0. 깃 프로젝트의 세 단계\n* 워킹 트리 (working tree) : 파일을 수정하는 공간이다. 스테이징을 통해 스테이징 에리어로 수정사항을 보낸다.\n* 스테이징 에리어 (staging area) : 커밋을 위한 임시 스냅샷을 저장하는 공간이다. 커밋을 통해 깃 리포지토리로 수정사항을 전달해서 영구적인 스냅샷으로 만들 수 있다.\n* 깃 리포지토리, 즉 깃 르포 (git repository) : 커밋된 스냅샷을 모두 보관하고 있는 공간이다. 필요에 따라서 버전을 되돌리거나 변화해온 수정 내역을 살펴볼 수 있다.\n\n\n## 1. 배시 쉘 명령어 (Bash shell commands)\n* 디렉토리 .git 내 모든 파일 출력\n```bash\n# look inside a git directory\nls -l .git/\n```\n* 숨겨진 파일을 포함해 현재 디렉토리에 위치한 모든 파일 출력\n```bash\n# list files with a dot (hidden files)\nls -la\n```\n* 파일 file_name.py 생성하기\n```bash\n# create a file\ntouch file_name.py\n```\n* atom 에디터로 파일 file_name.py 열기\n```bash\n# open a file with atom editor\natom file_name.py\n```\n* 파일 file_name.py 내용 쉘에서 보기\n```bash\n# lookup a file\ncat file_name.py\n```\n\n## 2. 설정 명령어 (Configuration commands)\n* 깃 현재 설정 출력하기 \n```bash\n# check current configuration\ngit config -l\n```\n* 깃의 이름, 이메일 설정 변경하기\n```bash\n# change configuration\ngit config --global user.name \"user_name\"\ngit config --global user.email \"user_email\"\n```\n* 깃허브 키를 15분 동안 캐시하기\n```bash\n# cache github key for 15 minutes\ngit config --global credential.helper cache\n```\n\n## 3. 커밋 명령어 (Commit commands)\n* 현재 디렉토리에서 새로운 깃 르포 생성하기\n```bash\n# initialize an empty git repository in current directory\ngit init\n```\n* 현재 워킹 트리의 정보 출력하기\n```bash\n# get information of current working tree\ngit status\n```\n\n### 커밋하기\n* 파일 file_name.py를 스테이징 에리어에 올리기 (커밋 준비)\n```bash\n# command git to track follwing file\ngit add file_name.py\n```\n* 커밋 메시지 창을 열며 현재 스테이징 에리어에 있는 것을 전부 커밋하기\n```bash\n# commit everything in current staging area\n# opens a text editor to enter a commit message\ngit commit\n```\n* 커밋 메시지를 입력하지 않고 커밋하기\n```bash\n# stage changes to tracked file & commit in one step\ngit commit -a\n```\n* 간략한 커밋 메시지 commit message와 함께 커밋하기\n```bash\n# stage & commit & enter message\ngit commit -a -m \"commit message\"\n```\n\n### 커밋 진행상황 보기\n* 모든 커밋 히스토리 출력하기\n```bash\n# check history of all commits\ngit log\n```\n* 각 커밋에서 수정된 사항을 줄 별로 출력하기\n```bash\n# show actual lines that changed in each commit\ngit log -p\n```\n* 커밋의 통계 정보 출력하기\n```bash\n# show statistics about the changes in the commit\ngit log --stat\n```\n* 커밋의 브랜치 트리 출력하기\n```bash\n# show commit branch tree\ngit log --graph --oneline --all\n```\n* 커밋 아이디 commit_id에 해당하는 커밋 정보 출력하기\n```bash\n# show the information about the commit and associated petches\ngit show [commit_id]\n```\n* commit_ id1과 commit_ id2에 해당하는 두 커밋 비교하기\n```bash\n# similar to Linux diff command\ngit diff [commit_id1] [commit_id2]\n```\n* 스테이징 되었지만 커밋되지 않은 파일 출력하기\n```bash\n# alias to --cached, show all staged but not commited files\ngit diff --staged\n```\n* 파일 file1.py의 이름을 file2.py로 변경하기\n```bash\n# rename file1 with file2\n# similar to Linux mv command\ngit mv [file1.py] [file2.py]\n```\n* 파일 file_name.py 삭제하기\n```bash\n# remove file_name.py from working space\n# similar to Linux rm command\ngit rm [file_name.py]\n```\n\n### 커밋 되돌리기\n* HEAD가 가리키는 브랜치가 commit_id를 가리키게 하기\n```bash\n# resets the repo in the Index, the next snapshot to commit\ngit reset --soft [commit_id]\n```\n* HEAD 브랜치를 이동하고 스테이징 에리어를 리셋하기\n```bash\n# update Index to the snapshot that HEAD is pointing \ngit reset --mixed [commit_id]\n```\n* HEAD 브랜치를 이동하고 스테이징 에리어와 워킹 디렉토리를 리셋하기\n```bash\n# update Index to the snapshot that HEAD is pointing \ngit reset --hard [commit_id]\n```\n* 현재 스테이징 에리어에 있는 내용을 커밋 내용으로 덮어쓰기\n```bash\n# make changes to commits after-the-fact on local commits\ngit commit --amend\n```\n* 히스토리를 유지한채 새로운 커밋으로 커밋 commit_id로 되돌리기\n```bash\n# make a new commit which rolls back a previous commit\ngit revert HEAD/[commit_id]\n```\n\n\n## 4. 브랜치 명령어 (Branch commands)\n* 모든 브랜치 출력하기\n```bash\n# list all branches\ngit branch\n```\n* 읽기 전용 원격 브랜치 출력하기\n```bash\n# shows read-only remote branches\ngit branch -r\n```\n* 브랜치 branch_name 생성하기\n```bash\n# creates the branch_name branch\ngit branch [branch_name]\n```\n* 브랜치 branch_name으로 이동하기\n```bash\n# switch to branch_name\ngit checkout [branch_name]\n```\n* 브랜치 branch_name을 생성하고 그 브랜치로 위치 이동하기\n```bash\n# creates a new branch and switches to it\ngit checkout -b [branch_name]\n```\n* 브랜치 branch_name 삭제하기\n```bash\n# deletes the branch branch_name\ngit branch -d [branch_name]\n```\n* 브랜치 branch_name 삭제 강제하기\n```bash\n# forcibly deletes the branch\ngit branch -D [branch_name]\n```\n* 브랜치 branch_name을 마스터 브랜치로 합치기\n```bash\n# joins branches together to the master branch\ngit merge [branch_name]\n```\n* 브랜치 충돌(merge conflicts)이 발생했을 때, 머지 취소하기\n```bash\n# when merge conflicts, abort merge action\ngit merge --abort\n```\n\n\n## 5. 깃허브 명령어 (Github commands)\n\n* 로컬 환경에 URL로 원격 르포 복제하기\n```bash\n# clone a remote repository into a local workspace\ngit clone [URL] \n```\n* 로컬 파일을 원격 르포에 푸시하기\n```bash\n# push commits from local repo to a remote repo\ngit push\n```\n* 원격 르포의 커밋을 로컬 환경에 별도의 브랜치로 복사해오기\n```bash\n# copy the commits done in the remote repository\ngit fetch\n```\n* 원격 르포의 커밋을 로컬 환경의 브랜치와 머지하기\n```bash\n# fetch from remote & merge\ngit pull\n```\n* 원격 르포 출력하기\n```bash\n# List remote repos\ngit remote\n```\n* 원격 르포 URL 출력하기\n```bash\n# show URL of remote repo\ngit remote -v\n```\n* 원격 르포 remote_name 정보 출력하기\n```bash\n# Describes a single remote repo\ngit remote show [remote_URL]\n```\n* 원격 르포의 업데이트를 로컬 환경에 불러오기\n```bash\n# Fetches the most up-to-date objects\ngit remote update\n```\n* 로컬 르포가 연결된 원격 르포 new-url로 이전하기\n```bash\n# transfer a repository from origin to [new-url]\ngit remote set-url origin [new-url]\n```\n* 브랜치 branch_name의 베이스 커밋을 바꾸기\n```bash\n# change the base commit used for the branch [branch_name]\ngit rebase [branch_name]\n```\n\n\n\n## 더 참고할 자료\n1. Git Docs ([link](https://git-scm.com/doc))\n2. GitHub Docs ([link](https://docs.github.com/en))\n3. Coursera, Google, Introduction to Git and Github ([link](https://www.coursera.org/learn/introduction-git-github))\n","excerpt":"분산 버전 관리 시스템인 깃 명령어(git commands)를 쉽게 볼 수 있도록 정리한 문서입니다. 0. 깃 프로젝트의 세 단계 워킹 트리 (working tree) : 파일을 수정하는 공간이다. 스테이징을 통해 스테이징 에리어로 수정사항을 보낸다…","fields":{"slug":"/git_cheat_sheet/"},"frontmatter":{"date":"Feb 04, 2022","title":"깃 치트 시트 (Git Cheat Sheet)","tags":["Git"],"update":"Mar 01, 2022"}}}]}},"pageContext":{}},"staticQueryHashes":["2027115977","694178885"]}